{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn \n",
    "\n",
    "**Scikit-learn** (http://scikit-learn.org/) is an open-source machine learning library for Python that offers a variety of regression, classification and clustering algorithms.\n",
    "\n",
    "WE are going to classify ham or spam sms. ITs a binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup:\n",
    "\n",
    "use anaconda prompt\n",
    "> `conda install scikit-learn`\n",
    "\n",
    "> `pip install -U scikit-learn`\n",
    "\n",
    "Scikit-learn additionally requires that NumPy and SciPy be installed. For more info visit http://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data\n",
    "For this exercise we'll be using the **SMSSpamCollection** dataset from [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) that contains more than 5 thousand SMS phone messages.<br>You can check out the [**sms_readme**](../TextFiles/sms_readme.txt) file for more info.\n",
    "\n",
    "The file is a [tab-separated-values](https://en.wikipedia.org/wiki/Tab-separated_values) (tsv) file with four columns:\n",
    "> **label** - every message is labeled as either ***ham*** or ***spam***<br>\n",
    "> **message** - the message itself<br>\n",
    "> **length** - the number of characters in each message<br>\n",
    "> **punct** - the number of punctuation characters in each message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>273</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>96</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length  punct\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...      91      1\n",
       "5553   ham                        Hahaha..use your brain dear      27      2\n",
       "5554   ham  Well keep in mind I've only got enough gas for...      98      1\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...     153      5\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...      63      6\n",
       "5557   ham  No. I meant the calculation is the same. That ...     273     18\n",
       "5558   ham                             Sorry, I'll call later      22      2\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...      66      6\n",
       "5560   ham                  Anything lor. Juz both of us lor.      33      2\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...      70      3\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...      96      9\n",
       "5563   ham                                Ard 6 like dat lor.      19      1\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...      67      3\n",
       "5565   ham                                       Huh y lei...      12      3\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...     147      3\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...     160      8\n",
       "5568   ham               Will ü b going to esplanade fr home?      36      1\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57      7\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125      1\n",
       "5571   ham                         Rofl. Its true to its name      26      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('smsspamcollection.tsv', sep='\\t') # tsv is tab separated, csv is comma separated \n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)#I dont use the \"message\" column yet this is just an example for scikit!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values:\n",
    "Machine learning models NEED  complete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique() # DETERMINE YOUR UNIQUE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()  # DETERMINE NUMBER OF LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTANT!! We see that 4825 out of 5572 messages, or 86.6%, are ham. This means that any machine learning model we create has to perform **better than 86.6%** to beat random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>This dataset is extremely skewed. The mean value is 80.5 and yet the max length is 910. Let's plot this on a logarithmic x-axis.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label']=='ham']['length'],bins=bins,alpha=0.8)\n",
    "plt.hist(df[df['label']=='spam']['length'],bins=bins,alpha=0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.        ,   1.15      ,   1.3225    ,   1.520875  ,\n",
       "         1.74900625,   2.01135719,   2.31306077,   2.66001988,\n",
       "         3.05902286,   3.51787629,   4.04555774,   4.6523914 ,\n",
       "         5.35025011,   6.15278762,   7.07570576,   8.13706163,\n",
       "         9.35762087,  10.761264  ,  12.37545361,  14.23177165,\n",
       "        16.36653739,  18.821518  ,  21.6447457 ,  24.89145756,\n",
       "        28.62517619,  32.91895262,  37.85679551,  43.53531484,\n",
       "        50.06561207,  57.57545388,  66.21177196,  76.14353775,\n",
       "        87.56506841, 100.69982867, 115.80480298, 133.17552342,\n",
       "       153.15185194, 176.12462973, 202.54332419, 232.92482281,\n",
       "       267.86354623, 308.04307817, 354.2495399 , 407.38697088,\n",
       "       468.49501651, 538.76926899, 619.58465934, 712.52235824,\n",
       "       819.40071197, 942.31081877])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.15**(np.arange(0,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's a small range of values where a message is more likely to be spam than ham.\n",
    "\n",
    "Now let's look at the `punct` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean        4.177495\n",
       "std         4.623919\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         6.000000\n",
       "max       133.000000\n",
       "Name: punct, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punct'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Split the data into train & test sets:\n",
    "\n",
    "If we wanted to divide the DataFrame into two smaller sets, we could use\n",
    "> `train, test = train_test_split(df)`\n",
    "\n",
    "For our purposes let's also set up our Features (X) and Labels (y). The Label is simple - we're trying to predict the `label` column in our data. For Features we'll use the `length` and `punct` columns. *By convention, **X** is capitalized and **y** is lowercase.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "There are two ways to build a feature set from the columns we want. If the number of features is small, then we can pass those in directly:\n",
    "> `X = df[['length','punct']]`\n",
    "\n",
    "If the number of features is large, then it may be easier to drop the Label and any other unwanted columns:\n",
    "> `X = df.drop(['label','message'], axis=1)`\n",
    "\n",
    "These operations make copies of **df**, but do not change the original DataFrame in place. All the original data is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Feature and Label sets\n",
    "X = df[['length','punct']]  # note the double set of brackets\n",
    "y = df['label'] # I dont use the \"message\" column yet this is just an example for scikit!!!!\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (4457, 2)\n",
      "Testing Data Shape:  (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "#80percent training data\n",
    "#20 percent test data\n",
    "print('Training Data Shape:', X_train.shape)\n",
    "print('Testing Data Shape: ', X_test.shape)\n",
    "#X_train # LECTURES\n",
    "#y_train  # Exercises or Homeworks\n",
    "#X_test  # EXam\n",
    "#y_test  # answers of Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass these sets into a series of different training & testing algorithms and compare their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a Logistic Regression classifier\n",
    "One of the simplest multi-class classification tools is [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Scikit-learn offers a variety of algorithmic solvers; we'll use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression(solver='lbfgs')\n",
    "#lr_model = LogisticRegression()  # use shift + tab to see what kind of parameter tuning you can do!!\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[931  35]\n",
      " [145   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Create a prediction set:\n",
    "predictions = lr_model.predict(X_test)\n",
    "# Print a confusion matrix\n",
    "print(metrics.confusion_matrix(y_test,predictions)) #below confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3245    ham\n",
       "944     ham\n",
       "1044    ham\n",
       "2484    ham\n",
       "812     ham\n",
       "       ... \n",
       "4264    ham\n",
       "2439    ham\n",
       "5556    ham\n",
       "4205    ham\n",
       "4293    ham\n",
       "Name: label, Length: 1115, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>931</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ham  spam\n",
       "ham   931    35\n",
       "spam  145     4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can make the confusion matrix better by adding labels:\n",
    "df = pd.DataFrame(metrics.confusion_matrix(y_test,predictions), index=['ham','spam'], columns=['ham','spam'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=purple>These results are very bad! More spam messages were confused as ham (241) than correctly identified as spam (5), although a relatively small number of ham messages (46) were confused as spam.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.96      0.91       966\n",
      "        spam       0.10      0.03      0.04       149\n",
      "\n",
      "    accuracy                           0.84      1115\n",
      "   macro avg       0.48      0.50      0.48      1115\n",
      "weighted avg       0.76      0.84      0.80      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8385650224215246\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>This model performed *worse* than a classifier that assigned all messages as \"ham\" would have!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Train a naïve Bayes classifier:\n",
    "One of the most common - and successful - classifiers is [naïve Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[956  10]\n",
      " [149   0]]\n"
     ]
    }
   ],
   "source": [
    "predictions = nb_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>The total number of confusions dropped from **287** to **256**. [241+46=287, 246+10=256]</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.92       966\n",
      "        spam       0.00      0.00      0.00       149\n",
      "\n",
      "    accuracy                           0.86      1115\n",
      "   macro avg       0.43      0.49      0.46      1115\n",
      "weighted avg       0.75      0.86      0.80      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8573991031390135\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))\n",
    "#above spam is failing to predict any!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better, but still less accurate than 86.6%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# support vector machine (SVM) classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC(gamma='auto' ) #kernel='linear' gamma='auto'  kernel='poly'\n",
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run predictions and report on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[919  47]\n",
      " [ 82  67]]\n"
     ]
    }
   ],
   "source": [
    "predictions = svc_model.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.93       966\n",
      "        spam       0.59      0.45      0.51       149\n",
      "\n",
      "    accuracy                           0.88      1115\n",
      "   macro avg       0.75      0.70      0.72      1115\n",
      "weighted avg       0.87      0.88      0.88      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884304932735426\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))\n",
    "# this one was better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
