{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9ce1ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance     8\n",
      "Skewness    28\n",
      "Curtosis    36\n",
      "Entropy     17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "dataset =  pd.read_csv(\"bill_authenticationWithMissingData.csv\")\n",
    "\n",
    "missing_val_count_by_column = (dataset.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "986e5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer  # Imputer is for missing values\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer(strategy='constant')  #'most_frequent' #'mean'  #'constant'  # 'median'\n",
    "datasetClean = pd.DataFrame(my_imputer.fit_transform(dataset))\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "datasetClean.columns = dataset.columns\n",
    "# In general you can use this imputer without worrying about the missing values."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2ded64d",
   "metadata": {},
   "source": [
    "Pros:\n",
    "\n",
    "Easy and fast.\n",
    "Works well with small numerical datasets.\n",
    "Cons:\n",
    "\n",
    "Doesn’t factor the correlations between features. It only works on the column level.\n",
    "Will give poor results on encoded categorical features (do NOT use it on categorical features).\n",
    "Not very accurate.\n",
    "Doesn’t account for the uncertainty in the imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8a708e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (datasetClean.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c8402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   1]\n",
      " [  3 180]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99       229\n",
      "         1.0       0.99      0.98      0.99       183\n",
      "\n",
      "    accuracy                           0.99       412\n",
      "   macro avg       0.99      0.99      0.99       412\n",
      "weighted avg       0.99      0.99      0.99       412\n",
      "\n",
      "SVC: 99.03% \n"
     ]
    }
   ],
   "source": [
    "X = datasetClean.drop('Class', axis=1)  # these are lectures\n",
    "y = datasetClean['Class'] # these are results\n",
    "\n",
    "from sklearn.model_selection import train_test_split  #\n",
    " #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, shuffle=True,random_state=42)  # 80 percent training , 20 percent testing\n",
    "\n",
    "from sklearn.svm import SVC  # support vector machine - linear\n",
    "svclassifier = SVC() # kernel='linear'\n",
    "fitted = svclassifier.fit(X_train, y_train)\n",
    "y_pred = fitted.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('SVC: %.2f%% '%  (accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3c8f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db686111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from impyute.imputation.cs import fast_knn\n",
    "sys.setrecursionlimit(100000) #Increase the recursion limit of the OS\n",
    "\n",
    "# start the KNN training\n",
    "KNNimputedDataset=fast_knn(dataset.values, k=30)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e84adf30",
   "metadata": {},
   "source": [
    "Can be much more accurate than the mean, median or most frequent imputation methods (It depends on the dataset).\n",
    "Cons:\n",
    "\n",
    "Computationally expensive. KNN works by storing the whole training dataset in memory.\n",
    "K-NN is quite sensitive to outliers in the data (unlike SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7e52a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   1]\n",
      " [  5 178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       229\n",
      "         1.0       0.99      0.97      0.98       183\n",
      "\n",
      "    accuracy                           0.99       412\n",
      "   macro avg       0.99      0.98      0.99       412\n",
      "weighted avg       0.99      0.99      0.99       412\n",
      "\n",
      "SVC: 98.54% \n"
     ]
    }
   ],
   "source": [
    "KNNimputedDataset = pd.DataFrame(KNNimputedDataset, columns = ['Variance','Skewness','Curtosis','Entropy','Class'])\n",
    "\n",
    "X2 = KNNimputedDataset.drop('Class', axis=1)  # these are lectures\n",
    "y2 = KNNimputedDataset['Class'] # these are results\n",
    "\n",
    "from sklearn.model_selection import train_test_split  #\n",
    " #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size = 0.30, shuffle=True,random_state=42)  # 80 percent training , 20 percent testing\n",
    "\n",
    "from sklearn.svm import SVC  # support vector machine - linear\n",
    "svclassifier = SVC() # kernel='linear'\n",
    "fitted = svclassifier.fit(X_train, y_train)\n",
    "y_pred = fitted.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('SVC: %.2f%% '%  (accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2d6db23",
   "metadata": {},
   "source": [
    "This type of imputation works by filling the missing data multiple times. Multiple Imputations (MIs) are much better than a single imputation as it measures the uncertainty of the missing values in a better way.\n",
    "\n",
    "mice: Multivariate Imputation by Chained\n",
    "Equations in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a19e35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "# start the MICE training\n",
    "miceImputerDataset=mice(dataset.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "791a642a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.6216    ,   8.6661    ,  -2.8073    ,  -0.44699   ,\n",
       "          0.        ],\n",
       "       [  4.5459    ,   8.1674    ,  -2.4586    ,  -1.4621    ,\n",
       "          0.        ],\n",
       "       [  3.866     ,  -2.6383    ,   1.9242    ,   0.10645   ,\n",
       "          0.        ],\n",
       "       ...,\n",
       "       [ -3.7503    , -13.4586    ,  17.5932    ,  -2.7771    ,\n",
       "          1.        ],\n",
       "       [ -3.5637    ,  -8.3827    ,  12.393     ,  -0.28076793,\n",
       "          1.        ],\n",
       "       [ -2.5419    ,  -0.65804   ,   2.6842    ,   1.1952    ,\n",
       "          1.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e4ce99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228   1]\n",
      " [  5 178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       229\n",
      "         1.0       0.99      0.97      0.98       183\n",
      "\n",
      "    accuracy                           0.99       412\n",
      "   macro avg       0.99      0.98      0.99       412\n",
      "weighted avg       0.99      0.99      0.99       412\n",
      "\n",
      "SVC: 98.54% \n"
     ]
    }
   ],
   "source": [
    "miceImputerDataset = pd.DataFrame(miceImputerDataset, columns = ['Variance','Skewness','Curtosis','Entropy','Class'])\n",
    "\n",
    "X2 = KNNimputedDataset.drop('Class', axis=1)  # these are lectures\n",
    "y2 = KNNimputedDataset['Class'] # these are results\n",
    "\n",
    "from sklearn.model_selection import train_test_split  #\n",
    " #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size = 0.30, shuffle=True,random_state=42)  # 80 percent training , 20 percent testing\n",
    "\n",
    "from sklearn.svm import SVC  # support vector machine - linear\n",
    "svclassifier = SVC() # kernel='linear'\n",
    "fitted = svclassifier.fit(X_train, y_train)\n",
    "y_pred = fitted.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('SVC: %.2f%% '%  (accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda20915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
